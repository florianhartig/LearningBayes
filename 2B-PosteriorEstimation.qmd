---
output: html_document
editor_options:
  chunk_output_type: console
---

```{r, include=FALSE}
set.seed(42)
```

# Posterior estimation

In the previous chapter, we have calculated our posterior distribution by multiplying prior and likelihood across a set of possible values, and then dividing by the sum of all those to standardize (this is the p(D) in the Bayesian formula). In all but the most simple models, this technique will not work. 

The reason is the so-called "curse of dimensionality" - imagine we have a statistical model with 20 parameters. Imagine we would say for each of this 20 parameters, we consider 20 possible values to evaluate the shape of the posterior - the number of values we would have to calculate would be 

$$
n = 20^{20} \approx 10^{26}
$$
which is probably larger than the memory of your computer. Thus, we need another way to calculate the shape of the posterior. The main method to do this in Bayesian inference is MCMC sampling. 


## What is an MCMC?

A Markov-Chain Monte-Carlo algorithm (MCMC) is an algorithm that jumps around in a density function (the so-called target function), in such a way that the probability to be at each point of the function is proportional to the target. To give you a simple example, let's say we wouldn't know how the normal distribution looks like. What you would then probably usually do is to calculate a value of the normal for a number of data points 


```{r}
values = seq(-10,10,length.out = 100)
density = dnorm(values)
plot(density)
```

To produce the same picture with an MCMC sampler, we will use teh BayesianTools package. Here the code to sample from a normal distribution: 

```{r}
library(BayesianTools)

density = function(x) dnorm(x, log = T) 
setup = createBayesianSetup(density, lower = -10, upper = 10)
out = runMCMC(setup, settings = list(iterations = 1000), sampler = "Metropolis")
plot(out)
```

What we get as a result is the so-called trace plot to the left, which shows us how the sampler jumped around in parameter space over time, and the density plot to the right, which shows us results of sampling from the normal distribution.

For this simple case, this is not particularly impressive, and looks exactly like the plot that we coded above, using the seq approach. However, as discussed above, the first approach will break down if we have high-dimensional multivariate distributions, wheras MCMC sampling also works for high-dimensional problems. 

::: callout-note
If you are interested in how an MCMC sampler works internally, you can look at Appendix @appendix-BayesianNumerics.
:::

## Fitting a linear regression with different MCMCs

So, how can we MCMC sample from statistical mdoels? We will discuss this by showing you different code options to fit the relationship between Ozone and Temperature in the dataset airquality, using a linear regression.

```{r}
plot(Ozone ~ Temp, data = airquality)
```

First, removing NAs and scaling all variables for convenience

```{r}
airqualityCleaned = airquality[complete.cases(airquality),]
airqualityCleaned = data.frame(scale(airqualityCleaned))
```

Just as a reminder: as a frequentist, you would fit the linear regression via 

```{r, message = F}
fit <- lm(Ozone ~ Temp, data = airqualityCleaned)
```

which would calculate the MLE and p-values for this model, and you could evaluate and summarize the results of this via 

```{r, message = F, eval = F}
summary(fit)
library(effects)
plot(allEffects(fit, partial.residuals = T))
par(mfrow = c(2,2))
plot(fit) # residuals
```

Now, we want to estimate the posterior distribution for this model, using MCMC sampling. I will show you four different options to do this:

### Bayesian analysis with brms

The simples option is to use brms. brms is a package that allows you to specify regression models in the formular syntax that is familiar to you from standard frequentist R function and packages such as lm, lme4, etc. The application is straightforward

```{r, message = F, echo=FALSE, results = 'hide'}
library(brms)
fit <- brm(Ozone ~ Temp, data = airqualityCleaned)
```

In the background, brms will translate you command into a STAN model (see below), fit this model, and return the results!

Here, we see the MCMC chains and the estimated posterior distributions for the intercept, Temperature slope and the residual error sigma. 

```{r}
plot(fit, ask = FALSE)
```

If we want, we could summary the results via 

```{r, eval = FALSE}
summary(fit)
plot(conditional_effects(fit), ask = FALSE)
```


### Bayesian analysis with STAN

As said, what the brms package does is to translate the model you specify into STAN code. STAN is an MCMC sampler that allows you to estimate posteriors for any statistical model. The model is provided to the sampler in a particular syntax. You can look at this syntax for your brms model, using

```{r, eval = F}
fit$model # model that is actually fit via 
```

This looks a bit overwhelming, but let's try to unpack this: in STAN, you don't have a particular function for the linear regression, you just tell the sampler how all your data points are connected. You do this in at least three steps, which I show in a more minimal code for a linear regression below:

1. The "data" section tells the sampler the dimensions of your data
2. The "parameter" section tells the sampler which parameters are to be estimated 
3. The "model" section tells the sampler how the parameters and the data are connected. In this case, we want a linear regression, so we write just the mathematical formula for a linear regression  y ~ normal(alpha + beta * x, sigma)

The model code is specified as a string, and then given to the sampler together with a list of the data.

```{r, message = F, results = 'hide'}
library(rstan)

stanmodelcode <- "
  data {
    int<lower=0> N;
    vector[N] Temp;
    vector[N] Ozone;
  }
  parameters {
    real intercept;
    real TempEffect;
    real<lower=0> sigma;
  }
  model {
    Ozone ~ normal(intercept + TempEffect * Temp, sigma);
  }
"

dat = list(Ozone = airqualityCleaned$Ozone, Temp = airqualityCleaned$Temp, N = nrow(airqualityCleaned))

fit <- stan(model_code = stanmodelcode, model_name = "example", 
            data = dat, iter = 2012, chains = 3, verbose = TRUE,
            sample_file = file.path(tempdir(), 'norm.csv')) 
```

The results are the same as before - here is how the MCMC jumps around in parameter space

```{r}
rstan::traceplot(fit)
```

and if you want summaries of the posterior, you can run: 

```{r, eval = F}
print(fit)
plot(fit)
```


### Bayesian analysis with JAGS

The second option is to use JAGS, w

The general approach in JAGS is to

1.  Set up a list that contains all the necessary data
2.  Write the model as a string in the JAGS specific BUGS dialect
3.  Compile the model and run the MCMC for an adaptation (burn-in) phase

```{r}
library(rjags)
Data = list(y = airqualityCleaned$Ozone, x = airqualityCleaned$Temp, nobs = nrow(airqualityCleaned))

modelCode = "
model{

  # Likelihood
  for(i in 1:nobs){
    mu[i] <- a*x[i]+ b
    y[i] ~ dnorm(mu[i],tau) # dnorm in jags parameterizes via precision = 1/sd^2
  }

  # Prior distributions
  
  # For location parameters, normal choice is wide normal
  a ~ dnorm(0,0.0001)
  b ~ dnorm(0,0.0001)

  # For scale parameters, normal choice is decaying
  tau ~ dgamma(0.001, 0.001)
  sigma <- 1/sqrt(tau) # this line is optional, just in case you want to observe sigma or set sigma (e.g. for inits)

}
"

# Specify a function to generate inital values for the parameters 
# (optional, if not provided, will start with the mean of the prior )
inits.fn <- function() list(a = rnorm(1), b = rnorm(1), tau = 1/runif(1,1,100))

# sets up the model
jagsModel <- jags.model(file= textConnection(modelCode), data=Data, init = inits.fn, n.chains = 3)

# MCMC sample from model
Samples <- coda.samples(jagsModel, variable.names = c("a","b","sigma"), n.iter = 5000)

# Plot the mcmc chain and the posterior sample 
plot(Samples)
summary(Samples)
```


### Bayesian analysis via BayesianTools

Here, we don't use a model specification language, but just write out the likelihood as an standard R function. The same can be done for the prior. For simplicity, in this case I just used flat priors using the lower / upper arguments.

```{r,  message = F, results='hide'}
library(BayesianTools)

likelihood <- function(par){
  a0 = par[1]
  a1 = par[2]
  sigma <- par[3]  
  logLikel = sum(dnorm(a0 + a1 * airqualityCleaned$Temp  - airqualityCleaned$Ozone , sd = sigma, log = T))
  return(logLikel)
}

setup <- createBayesianSetup(likelihood = likelihood, lower = c(-10,-10,0.01), upper = c(10,10,10), names = c("a0", "a1", "sigma"))

out <- runMCMC(setup)
```

```{r}
plot(out)
summary(out, start = 1000)
```

## Checking and expecting the results

Running the sampler again

```{r}
Samples <- coda.samples(jagsModel, variable.names = c("a","b","sigma"), n.iter = 5000)
```

### Convergence checks

Except for details in the syntax, the following is more or less the same for all samplers.

First thing should always be convergence checks. Visual look at the trace plots,

```{r}
plot(Samples)
```

We want to look at

1.  Convergence to the right parameter area (seems immediate, else you will see a slow move of the parameters in the traceplot). You should set burn-in after you have converged to the right area
2.  Mixing: low autocorrelation in the chain after convergence to target area (seems excellent in this case)

Further convergence checks should be done AFTER removing burn-in

```{r}
coda::acfplot(Samples)
```

Formal convergence diagnostics via

```{r}
coda::gelman.diag(Samples)
coda::gelman.plot(Samples)
```

No fixed rule but typically people require univariate psrf \< 1.05 or \< 1.1 and multivariate psrf \< 1.1 or 1.2

::: callout-caution
Note that the msrf rule was made for estimating the mean / median. If you want to estimate more unstable statistics, e.g. higher quantiles or other values such as the MAP or the DIC (see section on model selection), you may have to run the MCMC chain much longer to get stable outputs.

```{r, message = F, results='hide'}

  library(BayesianTools)
  bayesianSetup <- createBayesianSetup(likelihood = testDensityNormal, 
                                       prior = createUniformPrior(lower = -10,
                                                                  upper = 10))
  out = runMCMC(bayesianSetup = bayesianSetup, settings = list(iterations = 3000))
```

The plotDiagnostics function in package BT shows us how statistics develop over time

```{r}
plotDiagnostic(out)
```
:::

### Summary Table

```{r}
summary(Samples)
```

Highest Posterior Density intervals

```{r}
HPDinterval(Samples)
```

### Plots

Marginal plots show the parameter distribution (these were also created in the standard coda traceplots)

```{r}
BayesianTools::marginalPlot(Samples)
```

Pair correlation plots show 2nd order correlations

```{r}
# coda
coda::crosscorr.plot(Samples)
#BayesianTools
correlationPlot(Samples)
```

### Posterior predictive distribution

```{r}
dat = as.data.frame(Data)[,1:2]
dat = dat[order(dat$x),]
# raw data
plot(dat[,2], dat[,1])

# extract 1000 parameters from posterior from package BayesianTools
x = getSample(Samples, start = 300)
pred = x[,2] + dat[,2] %o% x[,1] 
lines(dat[,2], apply(pred, 1, median))
lines(dat[,2], apply(pred, 1, quantile, probs = 0.2), 
      lty = 2, col = "red")
lines(dat[,2], apply(pred, 1, quantile, probs = 0.8), 
      lty = 2, col = "red")

# alternative: plot all 1000 predictions in transparent color
plot(dat[,2], dat[,1])
for(i in 1:nrow(x)) lines(dat[,2], pred[,i], col = "#0000EE03")

# important point - so far, we have plotted 
# in frequentist, this is know as the confidence vs. the prediction distribution
# in the second case, we add th


pred = x[,2] + dat[,2] %o% x[,1] 
for(i in 1:nrow(x))  {
  pred[,i] = pred[,i] + rnorm(length(pred[,i]), 0, sd = x[i,3])
}

plot(dat[,2], dat[,1])
lines(dat[,2], apply(pred, 1, median))
lines(dat[,2], apply(pred, 1, quantile, probs = 0.2), lty = 2, col = "red")
lines(dat[,2], apply(pred, 1, quantile, probs = 0.8), lty = 2, col = "red")

#alternative plotting
polygon(x = c(dat[,2], rev(dat[,2])), 
        y = c(apply(pred, 1, quantile, probs = 0.2), 
              rev(apply(pred, 1, quantile, probs = 0.8))), 
        col = "#EE000020")
```

## Playing around with the pipeline

### Prior choice

Priors are not scale-free. What that means: dnorm(0,0.0001) might not be an uninformative prior, if the data scale is extremely small so that you might expect huge effect sizes - scaling all variables makes sure we have a good intuition of what "uninformative means".

**Task:** play with the following minimal script for a linear regression to understand how scaling parameter affects priors and thus posterior shapes. In particular, change

-   Multiply Ozone by 1000000 -\> will push sd estimates high
-   Multiply Temp by 0.0000001 -\> will push parameter estimates high

Then compare Bayesian parameter estimates and their uncertainty to Bayesian estimates. How would you have to change the priors to fix this problem and keep them uninformative?

**Task: 2** implement mildly informative priors as well as strong shrinkage priors in the regression. Question to discuss: should you put the shrinkage also in the intercept? Why should you center center variables if you include a shrinkage prior on the intercept?

```{r}
library(rjags)

dat = airquality[complete.cases(airquality),] 
# scaling happens here - change 
dat$Ozone = as.vector(scale(dat$Ozone))
dat$Temp = as.vector(scale(dat$Temp)) 


Data = list(y = dat$Ozone, 
            x = dat$Temp, 
            i.max = nrow(dat))

# Model
modelCode = "
model{

  # Likelihood
  for(i in 1:i.max){
    mu[i] <- Temp*x[i]+ intercept
    y[i] ~ dnorm(mu[i],tau)
  }

  # Prior distributions
  
  # For location parameters, typical choice is wide normal
  intercept ~ dnorm(0,0.0001)
  Temp ~ dnorm(0,0.0001)

  # For scale parameters, typical choice is decaying
  tau ~ dgamma(0.001, 0.001)
  sigma <- 1/sqrt(tau) # this line is optional, just in case you want to observe sigma or set sigma (e.g. for inits)

}
"

# Specify a function to generate inital values for the parameters (optional, if not provided, will start with the mean of the prior )
inits.fn <- function() list(a = rnorm(1), b = rnorm(1), 
                            tau = 1/runif(1,1,100))

# Compile the model and run the MCMC for an adaptation (burn-in) phase
jagsModel <- jags.model(file= textConnection(modelCode), data=Data, init = inits.fn, n.chains = 3)

# Run a bit to have a burn-in
update(jagsModel, n.iter = 1000)


# Continue the MCMC runs with sampling
Samples <- coda.samples(jagsModel, variable.names = c("intercept","Temp","sigma"), n.iter = 5000)


# Bayesian results
summary(Samples)

# MCMC results
fit <- lm(Ozone ~ Temp, data = dat)
summary(fit)
```

### Missing data

In the analysis above, we removed missing data. What happens if you are leaving the missing data in in a Jags model? Try it out and discuss what happens
